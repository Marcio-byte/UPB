{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4316459a",
   "metadata": {},
   "source": [
    "\n",
    "# Análisis de Sentimiento de Reviews del iPhone (UPB)\n",
    "\n",
    "**Autor:** Marcio Gonzales (UPB)  \n",
    "**Descripción:** Notebook listo para clase práctica (MBA) que:\n",
    "- Carga un CSV desde GitHub (**tu** repositorio).\n",
    "- Detecta automáticamente la columna de texto y, si existe, la de rating.\n",
    "- Ejecuta un **modelo multilingüe (1–5 estrellas)** para análisis de sentimiento.\n",
    "- Muestra distribuciones, compara contra rating real (si hay), colapsa a **POS/NEU/NEG**.\n",
    "- Genera **WordClouds** por clase (POS/NEU/NEG) y general.\n",
    "\n",
    "> Ejecuta las celdas en orden. En Colab, la primera ejecución descargará el modelo (tarda 30–60s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== 0) Dependencias =====\n",
    "!pip install -q transformers torch pandas numpy matplotlib wordcloud nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344944e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_colwidth', 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ccffa",
   "metadata": {},
   "source": [
    "## 1) Cargar tu CSV desde GitHub (URL raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae89ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reemplaza por la URL 'raw' de *tu* archivo en GitHub si cambia.\n",
    "RAW_URL = \"https://raw.githubusercontent.com/Marcio-byte/UPB/7df52ed2479cf04f54804c68dfb7cf6ba14f3759/iphone.csv\"\n",
    "# Alternativa (siempre el último de main, si el archivo está en 'main'):\n",
    "# RAW_URL = \"https://raw.githubusercontent.com/Marcio-byte/UPB/main/iphone.csv\"\n",
    "\n",
    "def read_csv_robusto(url):\n",
    "    tries = [\n",
    "        {\"encoding\": \"utf-8\", \"sep\": \",\"},\n",
    "        {\"encoding\": \"latin-1\", \"sep\": \",\"},\n",
    "        {\"encoding\": \"utf-8\", \"sep\": \";\"},\n",
    "        {\"encoding\": \"latin-1\", \"sep\": \";\"},\n",
    "    ]\n",
    "    last_err = None\n",
    "    for kw in tries:\n",
    "        try:\n",
    "            df = pd.read_csv(url, **kw)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise last_err\n",
    "\n",
    "df = read_csv_robusto(RAW_URL)\n",
    "\n",
    "print(\"Columnas originales:\", list(df.columns))\n",
    "display(df.head(3))\n",
    "print(\"Filas totales:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee25c2d",
   "metadata": {},
   "source": [
    "## 2) Detectar automáticamente columna de **texto** y (opcional) **rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalizar nombres de columnas (sin perder referencia al original)\n",
    "original_cols = list(df.columns)\n",
    "norm_cols = [re.sub(r'\\s+', '_', str(c).strip().lower()) for c in original_cols]\n",
    "norm_map = dict(zip(original_cols, norm_cols))\n",
    "inv_norm_map = {v: k for k, v in norm_map.items()}\n",
    "df.rename(columns=norm_map, inplace=True)\n",
    "\n",
    "# Candidatos ampliados\n",
    "candidatos_texto = {\n",
    "    \"review\", \"reviewtext\", \"text\", \"body\", \"content\", \"comentario\",\n",
    "    \"opinion\", \"comentarios\", \"review_body\", \"review_text\",\n",
    "    \"description\", \"summary\", \"title\"\n",
    "}\n",
    "candidatos_rating = {\n",
    "    \"overall\", \"rating\", \"ratings\", \"stars\", \"estrellas\", \"score\",\n",
    "    \"puntuacion\", \"star_rating\", \"ratingvalue\", \"rating_value\"\n",
    "}\n",
    "\n",
    "# Detectar texto\n",
    "col_texto = None\n",
    "for c in df.columns:\n",
    "    if c in candidatos_texto:\n",
    "        col_texto = c\n",
    "        break\n",
    "if col_texto is None:\n",
    "    # Heurística: mayor longitud media en columnas no numéricas\n",
    "    texto_cands = [c for c in df.columns if df[c].dtype == 'object']\n",
    "    if texto_cands:\n",
    "        col_texto = max(texto_cands, key=lambda c: df[c].astype(str).str.len().mean())\n",
    "\n",
    "# Detectar rating\n",
    "col_rating = None\n",
    "for c in df.columns:\n",
    "    if c in candidatos_rating:\n",
    "        col_rating = c\n",
    "        break\n",
    "\n",
    "print(\"Columna de texto detectada:\", col_texto, \" (original:\", inv_norm_map.get(col_texto, col_texto), \")\")\n",
    "print(\"Columna de rating detectada:\", col_rating, \" (original:\", inv_norm_map.get(col_rating, col_rating), \")\")\n",
    "\n",
    "# Limpieza suave\n",
    "df = df.dropna(subset=[col_texto]).reset_index(drop=True)\n",
    "\n",
    "# Parseo de rating (si existe)\n",
    "import math\n",
    "def parse_rating(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip()\n",
    "    # '★★★★★' -> 5\n",
    "    if set(s) <= set(\"★☆ \"):\n",
    "        return s.count(\"★\") if \"★\" in s else np.nan\n",
    "    # '5 out of 5'\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)', s)\n",
    "    if m:\n",
    "        try:\n",
    "            return float(m.group(1))\n",
    "        except:\n",
    "            return np.nan\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "if col_rating is not None:\n",
    "    df[col_rating + \"_num\"] = df[col_rating].apply(parse_rating)\n",
    "    vals = df[col_rating + \"_num\"]\n",
    "    if vals.notna().any():\n",
    "        inside = vals.dropna().between(1, 5).mean()\n",
    "        if inside >= 0.9:\n",
    "            df[col_rating + \"_num\"] = vals.clip(1, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b75f98",
   "metadata": {},
   "source": [
    "## 3) Modelo de sentimiento (multilingüe 1–5 estrellas) y predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14edd57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# Para clase: usar muestra para rapidez\n",
    "N = min(200, len(df))\n",
    "sample = df.sample(N, random_state=42).reset_index(drop=True)\n",
    "\n",
    "textos = sample[col_texto].astype(str).tolist()\n",
    "preds = classifier(textos)\n",
    "\n",
    "sample[\"pred_label\"] = [p[\"label\"] for p in preds]   # \"1 star\"...\"5 stars\"\n",
    "sample[\"pred_score\"] = [p[\"score\"] for p in preds]\n",
    "\n",
    "display(sample[[col_texto, \"pred_label\", \"pred_score\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b06dd5",
   "metadata": {},
   "source": [
    "## 4) Distribución de sentimiento predicho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "sample[\"pred_label\"].value_counts().sort_index().plot(kind=\"bar\", title=\"Distribución de sentimiento (predicho)\")\n",
    "plt.xlabel(\"Etiqueta\")\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db69c205",
   "metadata": {},
   "source": [
    "## 5) Comparación con rating real (si existe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b400aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "def label_to_num(lbl):\n",
    "    m = re.match(r\"(\\d+)\", str(lbl))\n",
    "    return int(m.group(1)) if m else np.nan\n",
    "\n",
    "if col_rating is not None:\n",
    "    sample[\"pred_num\"] = sample[\"pred_label\"].apply(label_to_num)\n",
    "    base_rating_col = col_rating + \"_num\" if (col_rating + \"_num\") in sample.columns else col_rating\n",
    "    if base_rating_col not in sample.columns:\n",
    "        sample[base_rating_col] = sample[base_rating_col].apply(parse_rating)\n",
    "    print(\"\\nTabla de contingencia (rating real vs predicción):\")\n",
    "    comp = sample.groupby([base_rating_col, \"pred_num\"]).size().unstack(fill_value=0)\n",
    "    display(comp)\n",
    "\n",
    "    # Discrepancias fuertes\n",
    "    malos = sample[\n",
    "        (sample[base_rating_col].round(0).between(4, 5)) &\n",
    "        (sample[\"pred_num\"].isin([1, 2]))\n",
    "    ][[col_texto, base_rating_col, \"pred_label\"]].head(5)\n",
    "\n",
    "    print(\"\\nEjemplos donde usuario puso ≥4★ pero el modelo predijo 1–2★:\")\n",
    "    for _, row in malos.iterrows():\n",
    "        print(f\"- ({row[base_rating_col]}★ vs {row['pred_label']}) {row[col_texto][:200]}...\")\n",
    "else:\n",
    "    print(\"No se detectó columna de rating en el CSV. Se omite la comparación.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38163fab",
   "metadata": {},
   "source": [
    "## 6) Colapsar a POS / NEU / NEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32167af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_sentiment_3(label):\n",
    "    s = str(label).strip().lower()\n",
    "    m = re.match(r\"(\\d+)\", s)\n",
    "    if m:\n",
    "        n = int(m.group(1))\n",
    "        if n <= 2:\n",
    "            return \"NEG\"\n",
    "        elif n == 3:\n",
    "            return \"NEU\"\n",
    "        else:\n",
    "            return \"POS\"\n",
    "    if \"neg\" in s: return \"NEG\"\n",
    "    if \"neu\" in s: return \"NEU\"\n",
    "    if \"pos\" in s or \"star\" in s: return \"POS\"\n",
    "    return \"NEU\"\n",
    "\n",
    "sample[\"pred_sent_3\"] = sample[\"pred_label\"].apply(to_sentiment_3)\n",
    "\n",
    "ax = sample[\"pred_sent_3\"].value_counts().reindex([\"NEG\",\"NEU\",\"POS\"]).plot(\n",
    "    kind=\"bar\", title=\"Distribución de sentimiento (POS / NEU / NEG)\"\n",
    ")\n",
    "ax.set_xlabel(\"Clase\"); ax.set_ylabel(\"Cantidad\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae277ef9",
   "metadata": {},
   "source": [
    "## 7) WordClouds por clase (POS / NEU / NEG) y general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26358850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dependencias y stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "stop_en = set(stopwords.words('english'))\n",
    "stop_es = set(stopwords.words('spanish'))\n",
    "stop_extra = {\n",
    "    \"iphone\", \"iphones\", \"apple\", \"ios\", \"pro\", \"max\", \"phone\", \"phones\",\n",
    "    \"cell\", \"celular\", \"celulares\", \"telefono\", \"teléfono\",\n",
    "    \"review\", \"reviews\", \"producto\", \"producto.\", \"producto,\", \"producto;\",\n",
    "    \"muy\", \"mas\", \"más\", \"etc\", \"rt\"\n",
    "}\n",
    "stop_all = set(STOPWORDS) | stop_en | stop_es | stop_extra\n",
    "\n",
    "def limpiar_texto(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)  # URLs\n",
    "    s = re.sub(r\"[@#]\\w+\", \" \", s)            # menciones/hashtags\n",
    "    s = re.sub(r\"[^a-záéíóúñü\\s]\", \" \", s)    # signos/números\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def generar_wordcloud(texto_concatenado, titulo=\"WordCloud\"):\n",
    "    if not texto_concatenado.strip():\n",
    "        print(f\"[{titulo}] No hay texto suficiente para generar la nube.\")\n",
    "        return\n",
    "    wc = WordCloud(width=1200, height=600, background_color=\"white\",\n",
    "                   stopwords=stop_all, max_words=200).generate(texto_concatenado)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(titulo)\n",
    "    plt.show()\n",
    "\n",
    "df_wc = sample.dropna(subset=[col_texto, \"pred_sent_3\"]).copy()\n",
    "df_wc[\"texto_limpio\"] = df_wc[col_texto].apply(limpiar_texto)\n",
    "\n",
    "texto_pos = \" \".join(df_wc.loc[df_wc[\"pred_sent_3\"]==\"POS\", \"texto_limpio\"].tolist())\n",
    "texto_neu = \" \".join(df_wc.loc[df_wc[\"pred_sent_3\"]==\"NEU\", \"texto_limpio\"].tolist())\n",
    "texto_neg = \" \".join(df_wc.loc[df_wc[\"pred_sent_3\"]==\"NEG\", \"texto_limpio\"].tolist())\n",
    "\n",
    "generar_wordcloud(texto_pos, \"Palabras clave (POS)\")\n",
    "generar_wordcloud(texto_neu, \"Palabras clave (NEU)\")\n",
    "generar_wordcloud(texto_neg, \"Palabras clave (NEG)\")\n",
    "\n",
    "# WordCloud general\n",
    "texto_all = \" \".join(df_wc[\"texto_limpio\"].tolist())\n",
    "generar_wordcloud(texto_all, \"Palabras clave (TODAS)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356568ea",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Notas para clase\n",
    "- Si la ejecución es lenta por la descarga del modelo, corre esta sección **antes** de empezar.\n",
    "- Ajusta `N` (muestra) en la celda del modelo si necesitas más/menos rapidez.\n",
    "- Si cambias el nombre o ubicación del CSV, actualiza `RAW_URL`.\n",
    "- Para comparar con rating real, asegúrate de que el CSV tenga una columna de estrellas reconocible.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
